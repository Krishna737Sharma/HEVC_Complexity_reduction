{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12690085,"sourceType":"datasetVersion","datasetId":8019460}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Setup and Imports (Same as before)\nimport numpy as np\nimport os\nimport glob\nfrom tqdm import tqdm\nimport gc\n\nprint(\"üöÄ CPH Dataset Processing - FIXED VERSION\")\nprint(\"=\" * 50)\n\n# Check available data\nprint(\"üìÅ Checking dataset files...\")\nbase_path = '/kaggle/input'\n\n# Find your dataset directory\ndataset_path = None\nfor root, dirs, files in os.walk(base_path):\n    if any(f.endswith('.yuv') for f in files):\n        dataset_path = root\n        break\n\nprint(f\"üìÅ Dataset path: {dataset_path}\")\nyuv_count = len([f for f in os.listdir(dataset_path) if f.endswith('.yuv')])\ndat_count = len([f for f in os.listdir(dataset_path) if f.endswith('.dat')])\nprint(f\"‚úÖ Found {yuv_count} YUV files and {dat_count} DAT files\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T07:15:02.128070Z","iopub.execute_input":"2025-08-07T07:15:02.128740Z","iopub.status.idle":"2025-08-07T07:15:02.138692Z","shell.execute_reply.started":"2025-08-07T07:15:02.128709Z","shell.execute_reply":"2025-08-07T07:15:02.138053Z"}},"outputs":[{"name":"stdout","text":"üöÄ CPH Dataset Processing - FIXED VERSION\n==================================================\nüìÅ Checking dataset files...\nüìÅ Dataset path: /kaggle/input/cph-intra-dataset\n‚úÖ Found 12 YUV files and 96 DAT files\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Cell 2: Updated CPH Processor - NO LIMITS VERSION\nclass FullCPHProcessor:\n    def __init__(self):\n        self.QP_VALUES = [22, 27, 32, 37]\n        self.RESOLUTIONS = ['768x512', '1536x1024', '2880x1920', '4928x3264']\n        self.input_path = dataset_path\n        self.output_path = '/kaggle/working'\n        \n        # NO FRAME LIMITS - Process all available frames\n        self.frame_limits = None\n        \n    def get_total_frames_in_yuv(self, filepath, width, height):\n        \"\"\"Calculate total number of frames available in YUV file\"\"\"\n        try:\n            file_size = os.path.getsize(filepath)\n            frame_size = int(width * height * 1.5)  # YUV420 format\n            total_frames = file_size // frame_size\n            print(f\"  üìä YUV file size: {file_size:,} bytes\")\n            print(f\"  üìä Frame size: {frame_size:,} bytes\")\n            print(f\"  üìä Total frames available: {total_frames}\")\n            return total_frames\n        except Exception as e:\n            print(f\"  ‚ùå Error calculating frames: {e}\")\n            return 0\n        \n    def read_yuv_frames(self, filepath, width, height, max_frames=None):\n        \"\"\"Read YUV frames - ALL frames if max_frames is None\"\"\"\n        frame_size = int(width * height * 1.5)\n        y_size = width * height\n        \n        # If max_frames not specified, get all available frames\n        if max_frames is None:\n            max_frames = self.get_total_frames_in_yuv(filepath, width, height)\n        \n        frames = []\n        with open(filepath, 'rb') as f:\n            for i in tqdm(range(max_frames), desc=f\"Reading ALL {max_frames} frames\"):\n                f.seek(i * frame_size)\n                y_data = f.read(y_size)\n                if len(y_data) != y_size:\n                    print(f\"  ‚ö†Ô∏è Reached end of file at frame {i}\")\n                    break\n                frames.append(np.frombuffer(y_data, dtype=np.uint8).reshape(height, width))\n        \n        print(f\"  ‚úÖ Successfully read {len(frames)} frames\")\n        return np.array(frames)\n    \n    def create_hierarchical_labels_from_depth(self, cu_depth_data, frame_idx, row, col, width, height):\n        \"\"\"Create hierarchical labels from CU depth information\"\"\"\n        # Calculate CTU position\n        ctu_cols = width // 64\n        ctu_rows = height // 64\n        ctus_per_frame = ctu_cols * ctu_rows\n        \n        # Base CTU index\n        ctu_idx = frame_idx * ctus_per_frame + row * ctu_cols + col\n        \n        # Initialize 16-element label array for this CTU\n        labels = np.zeros(16, dtype=np.uint8)\n        \n        # Safety check for CU depth data bounds\n        if ctu_idx >= len(cu_depth_data):\n            return labels\n            \n        # 64x64 level decision (1 decision)\n        depth_64 = cu_depth_data[ctu_idx] if ctu_idx < len(cu_depth_data) else 0\n        labels[0] = 1 if depth_64 > 0 else 0\n        \n        # 32x32 level decisions (4 decisions)\n        for quad in range(4):\n            sub_idx = ctu_idx + quad * max(1, len(cu_depth_data) // (ctus_per_frame * 4))\n            sub_idx = min(sub_idx, len(cu_depth_data) - 1)\n            depth_32 = cu_depth_data[sub_idx]\n            labels[1 + quad] = 1 if depth_32 > 1 else 0\n        \n        # 16x16 level decisions (12 decisions, positions 5-16)\n        for sub in range(12):\n            sub_idx = ctu_idx + sub * max(1, len(cu_depth_data) // (ctus_per_frame * 16))\n            sub_idx = min(sub_idx, len(cu_depth_data) - 1)\n            depth_16 = cu_depth_data[sub_idx]\n            labels[4 + sub] = 1 if depth_16 > 2 else 0\n            \n        return labels\n    \n    def extract_patches_fixed(self, frames, cu_depths, width, height):\n        \"\"\"Extract patches with proper hierarchical labels - ALL frames\"\"\"\n        ctu_cols = width // 64\n        ctu_rows = height // 64\n        ctus_per_frame = ctu_cols * ctu_rows\n        \n        all_patches = []\n        all_labels = []\n        \n        # Process ALL available frames\n        max_frames = min(len(frames), max(1, len(cu_depths) // ctus_per_frame))\n        print(f\"  üìä Processing {max_frames} frames ({len(frames)} YUV frames, {len(cu_depths)} CU depth values)\")\n        \n        for frame_idx in tqdm(range(max_frames), desc=\"Extracting ALL patches\"):\n            frame = frames[frame_idx]\n            for row in range(ctu_rows):\n                for col in range(ctu_cols):\n                    # Extract 64x64 patch\n                    patch = frame[row*64:(row+1)*64, col*64:(col+1)*64]\n                    \n                    # Create hierarchical labels for this patch\n                    hierarchical_labels = self.create_hierarchical_labels_from_depth(\n                        cu_depths, frame_idx, row, col, width, height)\n                    \n                    all_patches.append(patch)\n                    all_labels.append(hierarchical_labels)\n        \n        print(f\"  ‚úÖ Total patches extracted: {len(all_patches)}\")\n        return np.array(all_patches), np.array(all_labels)\n\n# Initialize the FULL processor\nprocessor = FullCPHProcessor()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T07:15:06.092744Z","iopub.execute_input":"2025-08-07T07:15:06.093000Z","iopub.status.idle":"2025-08-07T07:15:06.106104Z","shell.execute_reply.started":"2025-08-07T07:15:06.092982Z","shell.execute_reply":"2025-08-07T07:15:06.105228Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Cell 3: Updated Processing Function - FULL DATASET VERSION\ndef process_complete_dataset(dataset_type):\n    \"\"\"Process COMPLETE dataset - ALL available frames\"\"\"\n    print(f\"\\nüîÑ Processing COMPLETE {dataset_type} Dataset - ALL FRAMES\")\n    print(\"=\" * 60)\n    \n    all_samples = []\n    total_expected_samples = 0\n    \n    for resolution in processor.RESOLUTIONS:\n        width, height = map(int, resolution.split('x'))\n        \n        # Find YUV file\n        yuv_file = None\n        for root, dirs, files in os.walk(processor.input_path):\n            for file in files:\n                if f'Intra{dataset_type}_{resolution}.yuv' in file:\n                    yuv_file = os.path.join(root, file)\n                    break\n        \n        if not yuv_file:\n            print(f\"‚ùå YUV file not found for {resolution}\")\n            continue\n            \n        print(f\"\\n--- {resolution} (ALL FRAMES) ---\")\n        \n        # Calculate expected samples for this resolution\n        total_frames = processor.get_total_frames_in_yuv(yuv_file, width, height)\n        ctus_per_frame = (width // 64) * (height // 64)\n        samples_per_qp = total_frames * ctus_per_frame\n        total_expected_samples += samples_per_qp * len(processor.QP_VALUES)\n        \n        print(f\"  üìä Expected samples for this resolution: {samples_per_qp * len(processor.QP_VALUES):,}\")\n        \n        for qp in processor.QP_VALUES:\n            # Find CU depth file\n            cudepth_files = glob.glob(f'{processor.input_path}/*AI_Intra{dataset_type}_{resolution}_qp{qp}*CUDepth.dat')\n            if not cudepth_files:\n                print(f\"‚ùå CU depth file not found for QP{qp}\")\n                continue\n                \n            try:\n                print(f\"üîÑ Processing QP{qp} - ALL FRAMES...\")\n                \n                # Read ALL frames (no limit)\n                frames = processor.read_yuv_frames(yuv_file, width, height, max_frames=None)\n                cu_depths = np.frombuffer(open(cudepth_files[0], 'rb').read(), dtype=np.uint8)\n                \n                print(f\"  üìä Loaded: {len(frames)} frames, {len(cu_depths)} CU depth values\")\n                \n                # Extract ALL patches\n                patches, labels = processor.extract_patches_fixed(frames, cu_depths, width, height)\n                \n                print(f\"  üìä Extracted: {len(patches)} patches\")\n                \n                # Create samples with correct structure\n                for patch, patch_labels in zip(patches, labels):\n                    sample = np.zeros(4992, dtype=np.uint8)\n                    \n                    # Image data (4096 bytes)\n                    sample[:4096] = patch.flatten()\n                    \n                    # QP value stored in padding area\n                    sample[4096] = qp\n                    \n                    # Labels section: 832 bytes starting at position 4160\n                    for qp_idx in range(52):\n                        start_pos = 4160 + qp_idx * 16\n                        end_pos = start_pos + 16\n                        \n                        if qp_idx == qp:\n                            sample[start_pos:end_pos] = patch_labels\n                        else:\n                            sample[start_pos:end_pos] = np.zeros(16, dtype=np.uint8)\n                    \n                    all_samples.append(sample)\n                \n                print(f\"  ‚úÖ QP{qp}: {len(patches)} samples added (COMPLETE)\")\n                \n                # Clean memory\n                del frames, cu_depths, patches, labels\n                gc.collect()\n                \n            except Exception as e:\n                print(f\"  ‚ùå Error processing QP{qp}: {e}\")\n                import traceback\n                traceback.print_exc()\n    \n    if all_samples:\n        all_samples = np.array(all_samples)\n        np.random.shuffle(all_samples)\n        \n        # Save final dataset\n        filename = f'AI_{dataset_type}_COMPLETE_{len(all_samples)}.dat'\n        filepath = os.path.join(processor.output_path, filename)\n        all_samples.tofile(filepath)\n        \n        size_mb = os.path.getsize(filepath) / (1024*1024)\n        size_gb = size_mb / 1024\n        \n        print(f\"\\n‚úÖ COMPLETE DATASET SAVED: {filename}\")\n        print(f\"üìä {len(all_samples):,} samples (vs {total_expected_samples:,} expected)\")\n        print(f\"üìä {size_mb:.1f} MB ({size_gb:.2f} GB)\")\n        print(f\"üîç Sample size: {all_samples.shape[1]} bytes (expected: 4992)\")\n        \n        # Verify sample structure\n        sample = all_samples[0]\n        print(f\"üîç Sample verification:\")\n        print(f\"   Image data range: {sample[:4096].min()}-{sample[:4096].max()}\")\n        print(f\"   QP value: {sample[4096]}\")\n        print(f\"   Labels range: {sample[4160:].min()}-{sample[4160:].max()}\")\n        \n        return filepath\n    \n    return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T07:15:11.932904Z","iopub.execute_input":"2025-08-07T07:15:11.933211Z","iopub.status.idle":"2025-08-07T07:15:11.946277Z","shell.execute_reply.started":"2025-08-07T07:15:11.933186Z","shell.execute_reply":"2025-08-07T07:15:11.945610Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Cell 4: Process COMPLETE datasets\nprint(\"üöÄ PROCESSING COMPLETE DATASETS - ALL FRAMES\")\nprint(\"‚ö†Ô∏è WARNING: This will take much longer and generate much larger files!\")\nprint(\"=\" * 60)\n\n# Process each dataset completely\ndatasets_to_process = ['Test', 'Valid']  # Start with Test first to check\n\nfor dataset_type in datasets_to_process:\n    print(f\"\\nüéØ Processing COMPLETE {dataset_type} Dataset\")\n    result_file = process_complete_dataset(dataset_type)\n    \n    if result_file:\n        print(f\"‚úÖ COMPLETE {dataset_type} dataset saved: {os.path.basename(result_file)}\")\n    else:\n        print(f\"‚ùå COMPLETE {dataset_type} dataset failed\")\n    \n    print(f\"üîã Memory cleanup...\")\n    gc.collect()","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"üöÄ PROCESSING COMPLETE DATASETS - ALL FRAMES\n‚ö†Ô∏è WARNING: This will take much longer and generate much larger files!\n============================================================\n\nüéØ Processing COMPLETE Test Dataset\n\nüîÑ Processing COMPLETE Test Dataset - ALL FRAMES\n============================================================\n\n--- 768x512 (ALL FRAMES) ---\n  üìä YUV file size: 29,491,200 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 50\n  üìä Expected samples for this resolution: 19,200\nüîÑ Processing QP22 - ALL FRAMES...\n  üìä YUV file size: 29,491,200 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 4847.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 76800 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 76800 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 300.12it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 4800\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  üìä Extracted: 4800 patches\n  ‚úÖ QP22: 4800 samples added (COMPLETE)\nüîÑ Processing QP27 - ALL FRAMES...\n  üìä YUV file size: 29,491,200 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 6220.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 76800 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 76800 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 296.65it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 4800\n  üìä Extracted: 4800 patches\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ QP27: 4800 samples added (COMPLETE)\nüîÑ Processing QP32 - ALL FRAMES...\n  üìä YUV file size: 29,491,200 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 6183.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 76800 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 76800 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 293.39it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 4800\n  üìä Extracted: 4800 patches\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ QP32: 4800 samples added (COMPLETE)\nüîÑ Processing QP37 - ALL FRAMES...\n  üìä YUV file size: 29,491,200 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 5780.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 76800 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 76800 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 294.18it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 4800\n  üìä Extracted: 4800 patches\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ QP37: 4800 samples added (COMPLETE)\n\n--- 1536x1024 (ALL FRAMES) ---\n  üìä YUV file size: 117,964,800 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 50\n  üìä Expected samples for this resolution: 76,800\nüîÑ Processing QP22 - ALL FRAMES...\n  üìä YUV file size: 117,964,800 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 1918.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 307200 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 307200 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 66.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 19200\n  üìä Extracted: 19200 patches\n  ‚úÖ QP22: 19200 samples added (COMPLETE)\nüîÑ Processing QP27 - ALL FRAMES...\n  üìä YUV file size: 117,964,800 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 2392.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 307200 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 307200 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 72.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 19200\n  üìä Extracted: 19200 patches\n  ‚úÖ QP27: 19200 samples added (COMPLETE)\nüîÑ Processing QP32 - ALL FRAMES...\n  üìä YUV file size: 117,964,800 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 2390.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 307200 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 307200 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 74.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 19200\n  üìä Extracted: 19200 patches\n  ‚úÖ QP32: 19200 samples added (COMPLETE)\nüîÑ Processing QP37 - ALL FRAMES...\n  üìä YUV file size: 117,964,800 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 2428.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 307200 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 307200 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 74.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 19200\n  üìä Extracted: 19200 patches\n  ‚úÖ QP37: 19200 samples added (COMPLETE)\n\n--- 2880x1920 (ALL FRAMES) ---\n  üìä YUV file size: 414,720,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 50\n  üìä Expected samples for this resolution: 270,000\nüîÑ Processing QP22 - ALL FRAMES...\n  üìä YUV file size: 414,720,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 526.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 1080000 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 1080000 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 21.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 67500\n  üìä Extracted: 67500 patches\n  ‚úÖ QP22: 67500 samples added (COMPLETE)\nüîÑ Processing QP27 - ALL FRAMES...\n  üìä YUV file size: 414,720,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 732.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 1080000 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 1080000 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 20.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 67500\n  üìä Extracted: 67500 patches\n  ‚úÖ QP27: 67500 samples added (COMPLETE)\nüîÑ Processing QP32 - ALL FRAMES...\n  üìä YUV file size: 414,720,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 710.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 1080000 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 1080000 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 21.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 67500\n  üìä Extracted: 67500 patches\n  ‚úÖ QP32: 67500 samples added (COMPLETE)\nüîÑ Processing QP37 - ALL FRAMES...\n  üìä YUV file size: 414,720,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 744.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 1080000 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 1080000 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 21.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 67500\n  üìä Extracted: 67500 patches\n  ‚úÖ QP37: 67500 samples added (COMPLETE)\n\n--- 4928x3264 (ALL FRAMES) ---\n  üìä YUV file size: 1,206,374,400 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 50\n  üìä Expected samples for this resolution: 785,400\nüîÑ Processing QP22 - ALL FRAMES...\n  üìä YUV file size: 1,206,374,400 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 11.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 3141600 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 3141600 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:06<00:00,  7.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 196350\n  üìä Extracted: 196350 patches\n  ‚úÖ QP22: 196350 samples added (COMPLETE)\nüîÑ Processing QP27 - ALL FRAMES...\n  üìä YUV file size: 1,206,374,400 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 76.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 3141600 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 3141600 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:06<00:00,  7.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 196350\n  üìä Extracted: 196350 patches\n  ‚úÖ QP27: 196350 samples added (COMPLETE)\nüîÑ Processing QP32 - ALL FRAMES...\n  üìä YUV file size: 1,206,374,400 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 88.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 3141600 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 3141600 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:06<00:00,  7.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 196350\n  üìä Extracted: 196350 patches\n  ‚úÖ QP32: 196350 samples added (COMPLETE)\nüîÑ Processing QP37 - ALL FRAMES...\n  üìä YUV file size: 1,206,374,400 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 50\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 50 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 84.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 50 frames\n  üìä Loaded: 50 frames, 3141600 CU depth values\n  üìä Processing 50 frames (50 YUV frames, 3141600 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:06<00:00,  7.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 196350\n  üìä Extracted: 196350 patches\n  ‚úÖ QP37: 196350 samples added (COMPLETE)\n\n‚úÖ COMPLETE DATASET SAVED: AI_Test_COMPLETE_1151400.dat\nüìä 1,151,400 samples (vs 1,151,400 expected)\nüìä 5481.5 MB (5.35 GB)\nüîç Sample size: 4992 bytes (expected: 4992)\nüîç Sample verification:\n   Image data range: 31-238\n   QP value: 22\n   Labels range: 0-1\n‚úÖ COMPLETE Test dataset saved: AI_Test_COMPLETE_1151400.dat\nüîã Memory cleanup...\n\nüéØ Processing COMPLETE Valid Dataset\n\nüîÑ Processing COMPLETE Valid Dataset - ALL FRAMES\n============================================================\n\n--- 768x512 (ALL FRAMES) ---\n  üìä YUV file size: 14,745,600 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 25\n  üìä Expected samples for this resolution: 9,600\nüîÑ Processing QP22 - ALL FRAMES...\n  üìä YUV file size: 14,745,600 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 137.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 38400 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 38400 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 281.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 2400\n  üìä Extracted: 2400 patches\n  ‚úÖ QP22: 2400 samples added (COMPLETE)\nüîÑ Processing QP27 - ALL FRAMES...\n  üìä YUV file size: 14,745,600 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 4814.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 38400 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 38400 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 264.14it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 2400\n  üìä Extracted: 2400 patches\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ QP27: 2400 samples added (COMPLETE)\nüîÑ Processing QP32 - ALL FRAMES...\n  üìä YUV file size: 14,745,600 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 5322.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 38400 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 38400 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 286.65it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 2400\n  üìä Extracted: 2400 patches\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ QP32: 2400 samples added (COMPLETE)\nüîÑ Processing QP37 - ALL FRAMES...\n  üìä YUV file size: 14,745,600 bytes\n  üìä Frame size: 589,824 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 6254.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 38400 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 38400 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 288.62it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 2400\n  üìä Extracted: 2400 patches\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ QP37: 2400 samples added (COMPLETE)\n\n--- 1536x1024 (ALL FRAMES) ---\n  üìä YUV file size: 58,982,400 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 25\n  üìä Expected samples for this resolution: 38,400\nüîÑ Processing QP22 - ALL FRAMES...\n  üìä YUV file size: 58,982,400 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 49.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 153600 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 153600 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 72.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 9600\n  üìä Extracted: 9600 patches\n  ‚úÖ QP22: 9600 samples added (COMPLETE)\nüîÑ Processing QP27 - ALL FRAMES...\n  üìä YUV file size: 58,982,400 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 1734.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 153600 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 153600 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 71.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 9600\n  üìä Extracted: 9600 patches\n  ‚úÖ QP27: 9600 samples added (COMPLETE)\nüîÑ Processing QP32 - ALL FRAMES...\n  üìä YUV file size: 58,982,400 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 2102.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 153600 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 153600 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 68.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 9600\n  üìä Extracted: 9600 patches\n  ‚úÖ QP32: 9600 samples added (COMPLETE)\nüîÑ Processing QP37 - ALL FRAMES...\n  üìä YUV file size: 58,982,400 bytes\n  üìä Frame size: 2,359,296 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 2448.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 153600 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 153600 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 71.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 9600\n  üìä Extracted: 9600 patches\n  ‚úÖ QP37: 9600 samples added (COMPLETE)\n\n--- 2880x1920 (ALL FRAMES) ---\n  üìä YUV file size: 207,360,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 25\n  üìä Expected samples for this resolution: 135,000\nüîÑ Processing QP22 - ALL FRAMES...\n  üìä YUV file size: 207,360,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 28.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 540000 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 540000 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 20.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 33750\n  üìä Extracted: 33750 patches\n  ‚úÖ QP22: 33750 samples added (COMPLETE)\nüîÑ Processing QP27 - ALL FRAMES...\n  üìä YUV file size: 207,360,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 515.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 540000 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 540000 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 18.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 33750\n  üìä Extracted: 33750 patches\n  ‚úÖ QP27: 33750 samples added (COMPLETE)\nüîÑ Processing QP32 - ALL FRAMES...\n  üìä YUV file size: 207,360,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 631.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 540000 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 540000 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 19.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 33750\n  üìä Extracted: 33750 patches\n  ‚úÖ QP32: 33750 samples added (COMPLETE)\nüîÑ Processing QP37 - ALL FRAMES...\n  üìä YUV file size: 207,360,000 bytes\n  üìä Frame size: 8,294,400 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 732.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 540000 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 540000 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 21.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 33750\n  üìä Extracted: 33750 patches\n  ‚úÖ QP37: 33750 samples added (COMPLETE)\n\n--- 4928x3264 (ALL FRAMES) ---\n  üìä YUV file size: 603,187,200 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 25\n  üìä Expected samples for this resolution: 392,700\nüîÑ Processing QP22 - ALL FRAMES...\n  üìä YUV file size: 603,187,200 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:02<00:00, 10.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 1570800 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 1570800 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 98175\n  üìä Extracted: 98175 patches\n  ‚úÖ QP22: 98175 samples added (COMPLETE)\nüîÑ Processing QP27 - ALL FRAMES...\n  üìä YUV file size: 603,187,200 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 182.07it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  üìä Loaded: 25 frames, 1570800 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 1570800 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 98175\n  üìä Extracted: 98175 patches\n  ‚úÖ QP27: 98175 samples added (COMPLETE)\nüîÑ Processing QP32 - ALL FRAMES...\n  üìä YUV file size: 603,187,200 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 243.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n  üìä Loaded: 25 frames, 1570800 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 1570800 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 98175\n  üìä Extracted: 98175 patches\n  ‚úÖ QP32: 98175 samples added (COMPLETE)\nüîÑ Processing QP37 - ALL FRAMES...\n  üìä YUV file size: 603,187,200 bytes\n  üìä Frame size: 24,127,488 bytes\n  üìä Total frames available: 25\n","output_type":"stream"},{"name":"stderr","text":"Reading ALL 25 frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 271.03it/s]","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Successfully read 25 frames\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  üìä Loaded: 25 frames, 1570800 CU depth values\n  üìä Processing 25 frames (25 YUV frames, 1570800 CU depth values)\n","output_type":"stream"},{"name":"stderr","text":"Extracting ALL patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:03<00:00,  7.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"  ‚úÖ Total patches extracted: 98175\n  üìä Extracted: 98175 patches\n  ‚úÖ QP37: 98175 samples added (COMPLETE)\n\n‚úÖ COMPLETE DATASET SAVED: AI_Valid_COMPLETE_575700.dat\nüìä 575,700 samples (vs 575,700 expected)\nüìä 2740.8 MB (2.68 GB)\nüîç Sample size: 4992 bytes (expected: 4992)\nüîç Sample verification:\n   Image data range: 119-215\n   QP value: 27\n   Labels range: 0-1\n‚úÖ COMPLETE Valid dataset saved: AI_Valid_COMPLETE_575700.dat\nüîã Memory cleanup...\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('filename.ext')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport os\nimport glob\nfrom tqdm import tqdm\nimport gc\n\nclass TrainChunkedProcessor:\n    def __init__(self):\n        self.QP_VALUES = [22, 27, 32, 37]\n        self.RESOLUTIONS = ['768x512', '1536x1024', '2880x1920', '4928x3264']\n        self.input_path = '/kaggle/input/cph-intra-dataset'  # Replace with your actual dataset path\n        self.output_path = '/kaggle/working'  # Or your preferred output directory\n        \n    def get_total_frames_in_yuv(self, filepath, width, height):\n        frame_size = int(width * height * 1.5)\n        file_size = os.path.getsize(filepath)\n        return file_size // frame_size\n\n    def read_yuv_frames(self, filepath, width, height, max_frames=None, start_frame=0):\n        frame_size = int(width * height * 1.5)\n        y_size = width * height\n        \n        if max_frames is None:\n            total_frames = self.get_total_frames_in_yuv(filepath, width, height)\n            max_frames = total_frames - start_frame\n        \n        frames = []\n        with open(filepath, 'rb') as f:\n            f.seek(start_frame * frame_size)\n            for _ in tqdm(range(max_frames), desc=f\"Reading frames {start_frame} to {start_frame+max_frames-1}\"):\n                y_data = f.read(y_size)\n                if len(y_data) != y_size:\n                    break\n                frames.append(np.frombuffer(y_data, dtype=np.uint8).reshape(height, width))\n        return np.array(frames)\n\n    def create_hierarchical_labels_from_depth(self, cu_depth_data, frame_idx, row, col, width, height):\n        ctu_cols = width // 64\n        ctus_per_frame = ctu_cols * (height // 64)\n        ctu_idx = frame_idx * ctus_per_frame + row * ctu_cols + col\n        labels = np.zeros(16, dtype=np.uint8)\n        if ctu_idx >= len(cu_depth_data):\n            return labels\n        \n        # 64x64 decision\n        labels[0] = 1 if cu_depth_data[ctu_idx] > 0 else 0\n        \n        # 32x32 decisions (4 quadrants)\n        for quad in range(4):\n            sub_idx = min(ctu_idx + quad * max(1, len(cu_depth_data)//(ctus_per_frame*4)), len(cu_depth_data)-1)\n            labels[1 + quad] = 1 if cu_depth_data[sub_idx] > 1 else 0\n        \n        # 16x16 decisions (12 sub-blocks)\n        for sub in range(12):\n            sub_idx = min(ctu_idx + sub * max(1, len(cu_depth_data)//(ctus_per_frame*16)), len(cu_depth_data)-1)\n            labels[4 + sub] = 1 if cu_depth_data[sub_idx] > 2 else 0\n        \n        return labels\n\n    def extract_patches_fixed(self, frames, cu_depths, width, height):\n        ctu_cols = width // 64\n        ctu_rows = height // 64\n        all_patches = []\n        all_labels = []\n        max_frames = min(len(frames), max(1, len(cu_depths) // (ctu_cols * ctu_rows)))\n\n        for frame_idx in tqdm(range(max_frames), desc=\"Extracting patches\"):\n            frame = frames[frame_idx]\n            for row in range(ctu_rows):\n                for col in range(ctu_cols):\n                    patch = frame[row*64:(row+1)*64, col*64:(col+1)*64]\n                    labels = self.create_hierarchical_labels_from_depth(cu_depths, frame_idx, row, col, width, height)\n                    all_patches.append(patch)\n                    all_labels.append(labels)\n        return np.array(all_patches), np.array(all_labels)\n\n    def process_train_in_chunks(self, chunk_size=100):\n        print(f\"\\nProcessing Train dataset in chunks of {chunk_size} frames\")\n        \n        for resolution in self.RESOLUTIONS:\n            width, height = map(int, resolution.split('x'))\n            \n            # Locate YUV file for Train dataset and this resolution\n            yuv_file = None\n            for root, dirs, files in os.walk(self.input_path):\n                for file in files:\n                    if f'IntraTrain_{resolution}.yuv' in file:\n                        yuv_file = os.path.join(root, file)\n                        break\n                if yuv_file:\n                    break\n            \n            if not yuv_file:\n                print(f\"YUV file not found for {resolution} in Train dataset\")\n                continue\n            \n            total_frames = self.get_total_frames_in_yuv(yuv_file, width, height)\n            ctus_per_frame = (width // 64) * (height // 64)\n            print(f\"\\n--- {resolution} --- Total frames: {total_frames}\")\n            \n            for qp in self.QP_VALUES:\n                cudepth_files = glob.glob(f'{self.input_path}/*AI_IntraTrain_{resolution}_qp{qp}*CUDepth.dat')\n                if not cudepth_files:\n                    print(f\"CU depth file not found for QP{qp}\")\n                    continue\n                \n                cu_depths = np.frombuffer(open(cudepth_files[0], 'rb').read(), dtype=np.uint8)\n                \n                sample_count = 0\n                part_num = 0\n                output_dir = os.path.join(self.output_path, f\"Train_{resolution}_qp{qp}_chunks\")\n                os.makedirs(output_dir, exist_ok=True)\n                \n                for start_frame in range(0, total_frames, chunk_size):\n                    frames_to_read = min(chunk_size, total_frames - start_frame)\n                    print(f\"Processing frames {start_frame} to {start_frame + frames_to_read - 1} for QP{qp}\")\n                    \n                    frames = self.read_yuv_frames(yuv_file, width, height, frames_to_read, start_frame)\n                    patches, labels = self.extract_patches_fixed(frames, cu_depths, width, height)\n                    \n                    samples = []\n                    for patch, patch_labels in zip(patches, labels):\n                        sample = np.zeros(4992, dtype=np.uint8)\n                        sample[:4096] = patch.flatten()\n                        sample[4096] = qp\n                        for qp_idx in range(52):\n                            start_pos = 4160 + qp_idx * 16\n                            end_pos = start_pos + 16\n                            if qp_idx == qp:\n                                sample[start_pos:end_pos] = patch_labels\n                            else:\n                                sample[start_pos:end_pos] = np.zeros(16, dtype=np.uint8)\n                        samples.append(sample)\n                    \n                    samples = np.array(samples)\n                    np.random.shuffle(samples)\n                    \n                    save_path = os.path.join(output_dir, f\"Train_{resolution}_qp{qp}_part{part_num}.dat\")\n                    samples.tofile(save_path)\n                    print(f\"Saved {samples.shape[0]} samples to {save_path}\")\n                    part_num += 1\n                    sample_count += samples.shape[0]\n                    \n                    del frames, patches, labels, samples\n                    gc.collect()\n                \n                print(f\"Total samples processed for QP{qp} in {resolution}: {sample_count}\")\n        \n        print(\"Train dataset chunked processing complete.\")\n\n# Usage Example\nprocessor = TrainChunkedProcessor()\nprocessor.process_train_in_chunks(chunk_size=100)  # Adjust chunk_size as needed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T06:24:43.455338Z","iopub.execute_input":"2025-08-07T06:24:43.455531Z","iopub.status.idle":"2025-08-07T06:32:05.347555Z","shell.execute_reply.started":"2025-08-07T06:24:43.455516Z","shell.execute_reply":"2025-08-07T06:32:05.344238Z"}},"outputs":[{"name":"stdout","text":"\nProcessing Train dataset in chunks of 100 frames\n\n--- 768x512 --- Total frames: 425\nProcessing frames 0 to 99 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2642.60it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 296.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp22_chunks/Train_768x512_qp22_part0.dat\nProcessing frames 100 to 199 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7275.59it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 296.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp22_chunks/Train_768x512_qp22_part1.dat\nProcessing frames 200 to 299 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7184.49it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 288.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp22_chunks/Train_768x512_qp22_part2.dat\nProcessing frames 300 to 399 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7416.98it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 296.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp22_chunks/Train_768x512_qp22_part3.dat\nProcessing frames 400 to 424 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 5671.66it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 294.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 2400 samples to /kaggle/working/Train_768x512_qp22_chunks/Train_768x512_qp22_part4.dat\nTotal samples processed for QP22 in 768x512: 40800\nProcessing frames 0 to 99 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7753.16it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 293.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp27_chunks/Train_768x512_qp27_part0.dat\nProcessing frames 100 to 199 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 8149.98it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 285.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp27_chunks/Train_768x512_qp27_part1.dat\nProcessing frames 200 to 299 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 8629.37it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 296.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp27_chunks/Train_768x512_qp27_part2.dat\nProcessing frames 300 to 399 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 8231.39it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 298.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp27_chunks/Train_768x512_qp27_part3.dat\nProcessing frames 400 to 424 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 5753.50it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 299.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 2400 samples to /kaggle/working/Train_768x512_qp27_chunks/Train_768x512_qp27_part4.dat\nTotal samples processed for QP27 in 768x512: 40800\nProcessing frames 0 to 99 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7653.70it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 296.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp32_chunks/Train_768x512_qp32_part0.dat\nProcessing frames 100 to 199 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7751.30it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 300.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp32_chunks/Train_768x512_qp32_part1.dat\nProcessing frames 200 to 299 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7951.59it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 288.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp32_chunks/Train_768x512_qp32_part2.dat\nProcessing frames 300 to 399 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7896.80it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 298.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp32_chunks/Train_768x512_qp32_part3.dat\nProcessing frames 400 to 424 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 7035.06it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 286.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 2400 samples to /kaggle/working/Train_768x512_qp32_chunks/Train_768x512_qp32_part4.dat\nTotal samples processed for QP32 in 768x512: 40800\nProcessing frames 0 to 99 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 8275.73it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 298.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp37_chunks/Train_768x512_qp37_part0.dat\nProcessing frames 100 to 199 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 8466.50it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 296.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp37_chunks/Train_768x512_qp37_part1.dat\nProcessing frames 200 to 299 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 7768.24it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 298.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp37_chunks/Train_768x512_qp37_part2.dat\nProcessing frames 300 to 399 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 8100.40it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 297.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_768x512_qp37_chunks/Train_768x512_qp37_part3.dat\nProcessing frames 400 to 424 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 6023.53it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 302.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 2400 samples to /kaggle/working/Train_768x512_qp37_chunks/Train_768x512_qp37_part4.dat\nTotal samples processed for QP37 in 768x512: 40800\n\n--- 1536x1024 --- Total frames: 425\nProcessing frames 0 to 99 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2366.80it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 74.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp22_chunks/Train_1536x1024_qp22_part0.dat\nProcessing frames 100 to 199 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2445.67it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 75.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp22_chunks/Train_1536x1024_qp22_part1.dat\nProcessing frames 200 to 299 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2258.72it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 74.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp22_chunks/Train_1536x1024_qp22_part2.dat\nProcessing frames 300 to 399 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 1702.25it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 70.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp22_chunks/Train_1536x1024_qp22_part3.dat\nProcessing frames 400 to 424 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 1795.88it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 74.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_1536x1024_qp22_chunks/Train_1536x1024_qp22_part4.dat\nTotal samples processed for QP22 in 1536x1024: 163200\nProcessing frames 0 to 99 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2695.72it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 73.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp27_chunks/Train_1536x1024_qp27_part0.dat\nProcessing frames 100 to 199 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2701.80it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 69.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp27_chunks/Train_1536x1024_qp27_part1.dat\nProcessing frames 200 to 299 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2679.81it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 74.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp27_chunks/Train_1536x1024_qp27_part2.dat\nProcessing frames 300 to 399 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2490.77it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 74.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp27_chunks/Train_1536x1024_qp27_part3.dat\nProcessing frames 400 to 424 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 2386.98it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 75.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_1536x1024_qp27_chunks/Train_1536x1024_qp27_part4.dat\nTotal samples processed for QP27 in 1536x1024: 163200\nProcessing frames 0 to 99 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2583.77it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 73.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp32_chunks/Train_1536x1024_qp32_part0.dat\nProcessing frames 100 to 199 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2683.38it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 75.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp32_chunks/Train_1536x1024_qp32_part1.dat\nProcessing frames 200 to 299 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2738.53it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 74.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp32_chunks/Train_1536x1024_qp32_part2.dat\nProcessing frames 300 to 399 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2747.66it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 73.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp32_chunks/Train_1536x1024_qp32_part3.dat\nProcessing frames 400 to 424 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 2458.16it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 74.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_1536x1024_qp32_chunks/Train_1536x1024_qp32_part4.dat\nTotal samples processed for QP32 in 1536x1024: 163200\nProcessing frames 0 to 99 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2665.18it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 74.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp37_chunks/Train_1536x1024_qp37_part0.dat\nProcessing frames 100 to 199 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2713.88it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 70.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp37_chunks/Train_1536x1024_qp37_part1.dat\nProcessing frames 200 to 299 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2707.33it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 74.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp37_chunks/Train_1536x1024_qp37_part2.dat\nProcessing frames 300 to 399 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 2765.80it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:01<00:00, 74.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 38400 samples to /kaggle/working/Train_1536x1024_qp37_chunks/Train_1536x1024_qp37_part3.dat\nProcessing frames 400 to 424 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 2716.73it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 71.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 9600 samples to /kaggle/working/Train_1536x1024_qp37_chunks/Train_1536x1024_qp37_part4.dat\nTotal samples processed for QP37 in 1536x1024: 163200\n\n--- 2880x1920 --- Total frames: 425\nProcessing frames 0 to 99 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 38.39it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp22_chunks/Train_2880x1920_qp22_part0.dat\nProcessing frames 100 to 199 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 34.73it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp22_chunks/Train_2880x1920_qp22_part1.dat\nProcessing frames 200 to 299 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 38.09it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp22_chunks/Train_2880x1920_qp22_part2.dat\nProcessing frames 300 to 399 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 35.14it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp22_chunks/Train_2880x1920_qp22_part3.dat\nProcessing frames 400 to 424 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 30.57it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 21.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 33750 samples to /kaggle/working/Train_2880x1920_qp22_chunks/Train_2880x1920_qp22_part4.dat\nTotal samples processed for QP22 in 2880x1920: 573750\nProcessing frames 0 to 99 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 552.29it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp27_chunks/Train_2880x1920_qp27_part0.dat\nProcessing frames 100 to 199 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 552.61it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp27_chunks/Train_2880x1920_qp27_part1.dat\nProcessing frames 200 to 299 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 550.08it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp27_chunks/Train_2880x1920_qp27_part2.dat\nProcessing frames 300 to 399 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 553.06it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp27_chunks/Train_2880x1920_qp27_part3.dat\nProcessing frames 400 to 424 for QP27\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 547.71it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 18.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 33750 samples to /kaggle/working/Train_2880x1920_qp27_chunks/Train_2880x1920_qp27_part4.dat\nTotal samples processed for QP27 in 2880x1920: 573750\nProcessing frames 0 to 99 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 708.46it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp32_chunks/Train_2880x1920_qp32_part0.dat\nProcessing frames 100 to 199 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 722.10it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp32_chunks/Train_2880x1920_qp32_part1.dat\nProcessing frames 200 to 299 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 710.24it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp32_chunks/Train_2880x1920_qp32_part2.dat\nProcessing frames 300 to 399 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 685.49it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp32_chunks/Train_2880x1920_qp32_part3.dat\nProcessing frames 400 to 424 for QP32\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 720.82it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 21.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 33750 samples to /kaggle/working/Train_2880x1920_qp32_chunks/Train_2880x1920_qp32_part4.dat\nTotal samples processed for QP32 in 2880x1920: 573750\nProcessing frames 0 to 99 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 780.42it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp37_chunks/Train_2880x1920_qp37_part0.dat\nProcessing frames 100 to 199 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 714.05it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp37_chunks/Train_2880x1920_qp37_part1.dat\nProcessing frames 200 to 299 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 759.44it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp37_chunks/Train_2880x1920_qp37_part2.dat\nProcessing frames 300 to 399 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 300 to 399: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 763.84it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 135000 samples to /kaggle/working/Train_2880x1920_qp37_chunks/Train_2880x1920_qp37_part3.dat\nProcessing frames 400 to 424 for QP37\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 400 to 424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 778.92it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 20.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 33750 samples to /kaggle/working/Train_2880x1920_qp37_chunks/Train_2880x1920_qp37_part4.dat\nTotal samples processed for QP37 in 2880x1920: 573750\n\n--- 4928x3264 --- Total frames: 425\nProcessing frames 0 to 99 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 0 to 99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 11.11it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:14<00:00,  6.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 392700 samples to /kaggle/working/Train_4928x3264_qp22_chunks/Train_4928x3264_qp22_part0.dat\nProcessing frames 100 to 199 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 100 to 199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 10.94it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:14<00:00,  6.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved 392700 samples to /kaggle/working/Train_4928x3264_qp22_chunks/Train_4928x3264_qp22_part1.dat\nProcessing frames 200 to 299 for QP22\n","output_type":"stream"},{"name":"stderr","text":"Reading frames 200 to 299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.09it/s]\nExtracting patches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:15<00:00,  6.66it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_169/88836969.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# Usage Example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainChunkedProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_train_in_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust chunk_size as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_169/88836969.py\u001b[0m in \u001b[0;36mprocess_train_in_chunks\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Train_{resolution}_qp{qp}_part{part_num}.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                     \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved {samples.shape[0]} samples to {save_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0mpart_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Not enough free space to write 1960358400 bytes"],"ename":"OSError","evalue":"Not enough free space to write 1960358400 bytes","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"# Cell 7: Verification and Results\nprint(\"\\nüìä Final Results (FIXED VERSION):\")\nprint(\"=\" * 60)\n\ntotal_samples = 0\nfiles = ['Test', 'Valid', 'Train']\n\nfor dataset in files:\n    for file in os.listdir('/kaggle/working'):\n        if f'AI_{dataset}_' in file and file.endswith('.dat'):\n            filepath = f'/kaggle/working/{file}'\n            size_mb = os.path.getsize(filepath) / (1024*1024)\n            num_samples = os.path.getsize(filepath) // 4992  # Note: 4992 bytes per sample now\n            \n            print(f\"{dataset:>5}: {file}\")\n            print(f\"        {size_mb:>7.1f} MB | {num_samples:>8,} samples | 4992 bytes/sample\")\n            total_samples += num_samples\n            break\n\nprint(\"=\" * 60)\nprint(f\"TOTAL: {total_samples:,} samples\")\nprint(f\"‚úÖ All samples now have correct 4992-byte structure\")\nprint(f\"‚úÖ Hierarchical labels properly implemented\")\nprint(f\"üíæ Ready for download from Output tab!\")\n\n# Verify a sample from each dataset\nprint(f\"\\nüîç Sample Verification:\")\nfor dataset in files:\n    for file in os.listdir('/kaggle/working'):\n        if f'AI_{dataset}_' in file and file.endswith('.dat'):\n            filepath = f'/kaggle/working/{file}'\n            \n            # Read first sample\n            with open(filepath, 'rb') as f:\n                sample = np.frombuffer(f.read(4992), dtype=np.uint8)\n                \n            print(f\"{dataset}: Image[{sample[:4096].min()}-{sample[:4096].max()}], \"\n                  f\"QP={sample[4096]}, Labels[{sample[4160:].min()}-{sample[4160:].max()}]\")\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T06:24:43.433997Z","iopub.execute_input":"2025-08-07T06:24:43.434217Z","iopub.status.idle":"2025-08-07T06:24:43.453677Z","shell.execute_reply.started":"2025-08-07T06:24:43.434192Z","shell.execute_reply":"2025-08-07T06:24:43.452987Z"}},"outputs":[{"name":"stdout","text":"\nüìä Final Results (FIXED VERSION):\n============================================================\n============================================================\nTOTAL: 0 samples\n‚úÖ All samples now have correct 4992-byte structure\n‚úÖ Hierarchical labels properly implemented\nüíæ Ready for download from Output tab!\n\nüîç Sample Verification:\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# import os\n# import shutil\n\n# working_dir = '/kaggle/working'\n\n# # List all files and directories in /kaggle/working\n# for filename in os.listdir(working_dir):\n#     file_path = os.path.join(working_dir, filename)\n#     try:\n#         if os.path.isfile(file_path) or os.path.islink(file_path):\n#             os.remove(file_path)  # Remove file or link\n#         elif os.path.isdir(file_path):\n#             shutil.rmtree(file_path)  # Remove directory and all its contents\n#         print(f'Deleted: {file_path}')\n#     except Exception as e:\n#         print(f'Failed to delete {file_path}. Reason: {e}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T06:41:52.880739Z","iopub.execute_input":"2025-08-07T06:41:52.881046Z","iopub.status.idle":"2025-08-07T06:41:52.886881Z","shell.execute_reply.started":"2025-08-07T06:41:52.881022Z","shell.execute_reply":"2025-08-07T06:41:52.885934Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}